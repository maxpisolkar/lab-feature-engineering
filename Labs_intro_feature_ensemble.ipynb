{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Intro to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Spaceship Titanic data. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\maxpi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\maxpi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\maxpi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\maxpi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\maxpi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "spaceship.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple strategies to handle missing data\n",
    "\n",
    "- Removing all rows or all columns containing missing data.\n",
    "- Filling all missing values with a value (mean in continouos or mode in categorical for example).\n",
    "- Filling all missing values with an algorithm.\n",
    "\n",
    "For this exercise, because we have such low amount of null values, we will drop rows containing any missing value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_clean = spaceship.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors is a distance based algorithm, and requeries all **input data to be numerical.**\n",
    "\n",
    "Let's only select numerical columns as our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_numerical = spaceship_clean.select_dtypes(include=['number'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also lets define our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (6606, 6)\n",
      "Target shape: (6606,)\n"
     ]
    }
   ],
   "source": [
    "y = spaceship_clean['Transported']\n",
    "\n",
    "X = spaceship_clean.select_dtypes(include=['number'])\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split the data into **features** and **target** variables and imported the **train_test_split** function, split X and y into X_train, X_test, y_train, and y_test. 80% of the data should be in the training set and 20% in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5284, 6)\n",
      "X_test shape: (1322, 6)\n",
      "y_train shape: (5284,)\n",
      "y_test shape: (1322,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will be using **KNN** as our predictive model.\n",
    "\n",
    "You need to choose between **Classificator** or **Regressor**. Take into consideration target variable to decide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a KNN instance without setting any hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN classifier accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations, you have just developed your first Machine Learning model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cabin** is too granular - transform it in order to obtain {'A', 'B', 'C', 'D', 'E', 'F', 'G', 'T'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop PassengerId and Name\n",
    "- For non-numerical columns, do dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxpi\\AppData\\Local\\Temp\\ipykernel_9296\\4144187153.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spaceship_clean['Cabin'] = spaceship_clean['Cabin'].str.split('/').str[0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spaceship_clean['Cabin'] = spaceship_clean['Cabin'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'F' 'A' 'G' 'E' 'C' 'D' 'T']\n"
     ]
    }
   ],
   "source": [
    "print(spaceship_clean['Cabin'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceship_clean_2= spaceship_clean.drop(columns=['PassengerId', 'Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP',\n",
       "       'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
       "       'Transported'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship_clean_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_num_cols = spaceship_clean_2.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "spaceship_clean_3 = pd.get_dummies(spaceship_clean_2, columns=non_num_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5284, 19)\n",
      "X_test shape: (1322, 19)\n",
      "y_train shape: (5284,)\n",
      "y_test shape: (1322,)\n"
     ]
    }
   ],
   "source": [
    "X = spaceship_clean_3.drop('Transported', axis=1)\n",
    "y = spaceship_clean_3['Transported'].astype(int) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN classifier accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection - now you will try to apply different ensemble methods in order to get a better model\n",
    "\n",
    "Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.7995461422087746\n",
      "Bagging Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       653\n",
      "           1       0.80      0.81      0.80       669\n",
      "\n",
      "    accuracy                           0.80      1322\n",
      "   macro avg       0.80      0.80      0.80      1322\n",
      "weighted avg       0.80      0.80      0.80      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "base_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "bagging_clf = BaggingClassifier(\n",
    "    estimator=base_knn,\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    bootstrap=True,  # Bagging\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
    "print(\"Bagging Report:\\n\", classification_report(y_test, y_pred_bagging))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting Accuracy: 0.7972768532526475\n",
      "Pasting Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       653\n",
      "           1       0.79      0.81      0.80       669\n",
      "\n",
      "    accuracy                           0.80      1322\n",
      "   macro avg       0.80      0.80      0.80      1322\n",
      "weighted avg       0.80      0.80      0.80      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pasting_clf = BaggingClassifier(\n",
    "    estimator=base_knn,\n",
    "    n_estimators=50,\n",
    "    max_samples=0.8,\n",
    "    bootstrap=False,  # Pasting\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pasting_clf.fit(X_train, y_train)\n",
    "y_pred_pasting = pasting_clf.predict(X_test)\n",
    "\n",
    "print(\"Pasting Accuracy:\", accuracy_score(y_test, y_pred_pasting))\n",
    "print(\"Pasting Report:\\n\", classification_report(y_test, y_pred_pasting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Bagging Accuracy: 0.802571860816944\n",
      "Scaled Bagging Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80       653\n",
      "           1       0.80      0.81      0.81       669\n",
      "\n",
      "    accuracy                           0.80      1322\n",
      "   macro avg       0.80      0.80      0.80      1322\n",
      "weighted avg       0.80      0.80      0.80      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_bagging_scaled = bagging_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Scaled Bagging Accuracy:\", accuracy_score(y_test, y_pred_bagging_scaled))\n",
    "print(\"Scaled Bagging Report:\\n\", classification_report(y_test, y_pred_bagging_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Pasting Accuracy: 0.7995461422087746\n",
      "Scaled Pasting Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       653\n",
      "           1       0.80      0.81      0.80       669\n",
      "\n",
      "    accuracy                           0.80      1322\n",
      "   macro avg       0.80      0.80      0.80      1322\n",
      "weighted avg       0.80      0.80      0.80      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pasting_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_pasting_scaled = pasting_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Scaled Pasting Accuracy:\", accuracy_score(y_test, y_pred_pasting_scaled))\n",
    "print(\"Scaled Pasting Report:\\n\", classification_report(y_test, y_pred_pasting_scaled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.25993599778055204\n",
      "RMSE: 0.37711598335410534\n",
      "R2 score: 0.431050800961703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "forest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_forest = forest.predict(X_test_scaled)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_forest))\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_forest)\n",
    "rmse = mse ** 0.5\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.27771737728234663\n",
      "RMSE: 0.3654235616311159\n",
      "R2 score: 0.4657842307233987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "gbr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_gbr = gbr.predict(X_test_scaled)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_gbr))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred_gbr) ** 0.5)\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_gbr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.35489533650286853\n",
      "RMSE: 0.4063108109678157\n",
      "R2 score: 0.33954935703682465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "ada.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ada = ada.predict(X_test_scaled)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_ada))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred_ada) ** 0.5)\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting fits the data best with the lowest RMSE and highest R². Random Forest has a slightly better MAE but worse RMSE and R². AdaBoost performed the worst overall.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'metric': 'manhattan', 'n_neighbors': 27, 'weights': 'uniform'}\n",
      "Best cross-validated accuracy: 0.7785768039907113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the grid of parameters\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1, 31),  # Try k from 1 to 30\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", grid_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
